\documentclass[main.tex]{subfiles}
\begin{document}

\section{Statistical methods in cosmology} \label{sec:statistical-methods}

% Ergodicity: temporal and spatial averages coincide
% Fair Sample Hypothesis: the universe is homogeneous and isotropic

% From \cite[sec.\ 4]{nataleNoteCorsoDi2017}.

\subsection{The statistics of fluctuations}

In order to study the statistical properties of fluctuations we need to start from an assumption: \emph{ergodicity}. 
The probabilities we will discuss are defined formally as corresponding to the likelihood of drawing a certain ``realization of the universe'' from a statistical ensemble of possible universes. 
We cannot, of course, analyze more than one of these realizations, but we can consider its \emph{spatial} statistics. 

All statistical properties can be derived as averages of appropriate functions; ergodicity is precisely the statement that spatial averages correspond to ensemble averages. 

With this established, let us discuss how we can characterize the fluctuations of, say, the density field \(\rho \) (although this approach can be applied to other fields). 
We start by defining \(\delta = (\rho - \rho_b) / \rho_b\):  this is the dimensionless fluctuation, which can range from \(-1\) to \(+ \infty \).
By definition, its average will be 0: \(\expval{ \delta } = 0\), so we need to average at least a product of two \(\delta \)'s in order to have a nonzero result. 
We evaluate them at two arbitrary point, \(x\) and \(x + r\): this would correspond to six degrees of freedom, but we lose three from homogeneity and two more from isotropy, therefore we only need to account for the modulus of \(r\). This motivates the definition 
%
\begin{align}
\xi (r) = \expval{ \delta (x) \delta (x+r)} 
\,,
\end{align}
%
which is called the \emph{two-point correlation function}.
By isotropy, we expect its Fourier transform to be a function of the modulus of the wavevector.
With this in mind, we write the following ansatz for the correlation function in Fourier space, in terms of the \textbf{power spectral density} \(P\): 
%
\begin{align}
\expval{ \delta (k_1 ) \delta (k_2)} = (2 \pi )^3 \delta^{(3)}(k_1 + k_2 ) P(\abs{k_1 })
\,,
\end{align}
%
where \(\delta (k)\) is the Fourier transform of \(\delta (x)\) (they are denoted by the same letter despite being different functions, we distinguish them by the argument): 
%
\begin{align}
\delta (x) = \int \frac{ \dd[3]{x}}{(2 \pi )^3} e^{i k \cdot x} \delta (k)
\,.
\end{align}
% 

Let us then check that the ansatz is indeed correct:
%
\begin{align}
\xi (r) &= \int 
\frac{ \dd[3]{k_1}}{(2 \pi )^3} 
\frac{ \dd[3]{k_2}}{(2 \pi )^3} 
\exp(i k_1 x + i k_2 x + i k_2 r)
\expval{ \delta (k_1 ) \delta (k_2 )}  \\
&= \int 
\frac{ \dd[3]{k_1}}{(2 \pi )^3} 
\frac{ \dd[3]{k_2}}{(2 \pi )^3} 
\exp(i k_1 x + i k_2 x + i k_2 r)
(2 \pi )^3 \delta^{(3)} (k_1 + k_2 ) P(k_1 )  \\
&= \int 
\frac{\dd[3]{k_1}}{(2 \pi )^3}
\exp(- i k_1  r)
P(k_1 )   \\
&=
\int \frac{ \dd[3]{k}}{(2 \pi )^3}
\exp(i \abs{k} \abs{r} \cos \theta )
P( \abs{k})
\,.
\end{align}

This shows that \(P(\abs{k})\) is the Fourier transform of the two-point correlation function \(\xi (r)\). 
We can simplify this expression making use of the fact that there is no angular dependence in the integral in \(\dd[3]{k_1}\): 
the computation yields 
%
\begin{align}
\xi (r) = \frac{1}{2 \pi^2} \int_0^{\infty } \dd{k} k^2 P(\abs{k}) j_0 (kr)
\,,
\end{align}
%
where \(j_0 \) is a Bessel function defined by 
%
\begin{align}
j_0 (x) =  \frac{1}{2} \int_0^{\pi } e^{i x \cos \theta } \sin \theta \dd{\theta } 
\,.
\end{align}


If we evaluate the two-point correlation function \(\xi \) at 0 we find the variance of the density fluctuation field at a generic point: \(\xi (0) = \expval{ \delta (x) \delta (x)} = \sigma^2\), which can be expressed as 
%
\begin{align}
\sigma^2 = \xi (0) = \int \frac{ \dd[3]{k}}{(2 \pi )^3} P(\abs{k})
\,.
\end{align}
%

The physical meaning of the power spectrum \(P(\abs{k})\) is to describe the distribution of the power of the perturbations into the various spatial frequencies; the previous expression shows that the variance at each point can be recovered by integrating it. 

The shape of this power spectrum in the early universe has been measured through the correlations in the CMB by the Planck satellite: the spectrum is well described by a powerlaw, \(P(k) = A k^{n_s}\), with \(n_s = \num{0.9665 +- 0.0038}\) \cite[eq.\ 38]{planckcollaborationPlanck2018Results2019}.

A value of \(n_s = 0\) would correspond to frequency-independent \emph{white noise}; \(n_s = 1\) would instead indicate exact \emph{scale invariance}, and this is called a Harrison-Zel'dovich spectrum.
The measurement of \(n_s\) being slightly smaller than 1 indicates the presence of more energy at longer wavelengths, which is called a \emph{red tilt}. 

With this value, we can see that the integral giving \(\sigma^2\) diverges in the ultraviolet (\(k \to \infty\)). 
This divergence is not physical, since cosmic structure does not extend to arbitrarily small scales. Therefore, we fix the problem by introducing a \emph{spatial filter} \(W(r, R)\), where \(r\) is the spatial radius of interest while \(R\) is a fixed characteristic radius below which we do not consider structures. This filter is better characterized through its Fourier transform, \(\widetilde{W}(k, R)\): we use a filtered field like 
%
\begin{align}
\delta_R (k) &= \widetilde{W}(k, R) \delta (k)  \\
\delta _R(r) &= \int \dd[3]{y} W(\abs{x-y}, R) \delta (x)
\,.
\end{align}

The convolution in real space can be visually interpreted as a smoothing over scales of \(R\) (of course, the exact workings of this depend on the precise shape of \(W\)); in Fourier space we have a simpler multiplication.

There are different ways of choosing \(\widetilde{W}(k, R)\), which have in common the fact that they attain high values for \(k \ll R^{-1}\) and they go to zero for \(k \gg R^{-1}\). 
One must be careful when choosing a filter: a sharp filter in real space corresponds to a very broad filter in Fourier space, and vice versa. 
The power spectrum is transformed like \(P(k) \to \widetilde{W}^2(k, R) P(k)\) by the application of the filter.

\subsection{Peak functions}

We have two main observational channels to study perturbations: the CMB and the positions of galaxies.
With the latter we are not probing the whole perturbation spectrum: instead, we can describe the \emph{peaks} of the perturbation, which undergo gravitational collapse to form galaxies. 

The approach by \textcite[]{matarresePathintegralApproachLargescale1986} is to start from the fact that at each point we have a distribution with a variance \(\sigma_R^2\) (if we are using a smoothing scale of \(R\)), so we can define the density 
%
\begin{align}
\rho_{\nu , R} = \Theta (\delta (x) - \nu \sigma _R)
\,,
\end{align}
%
where \(\nu \) is a real number of order 1, and \(\Theta \) is the Heaviside function: this density characterizes the points which are \(\nu \) standard deviations above the background. 
We can study the \(N\)-point correlation functions of this ``boolean density'': 
%
\begin{align}
\Pi^{(N)}_{\nu , R} (x_1 \dots x_N) = \expval{ \prod_{r=1}^{N} \rho _{\nu , R} (x_r)}
\,,
\end{align}
%
which, roughly, speaking, can quantify the probability that we will find galaxies in the positions \(x_1, \dots, x_N\) if we choose \(\nu \) appropriately. 

A seminal paper by \textcite[]{bardeenStatisticsPeaksGaussian1986} systematically characterized the statistics of these peaks in the case of a Gaussian density perturbation field.

% Path integral techniques have found many applications in the study of these peaks.
% \textcite[]{bertschingerPathIntegralMethods1987} was the first to use them for the generation of \emph{constrained realizations}: one can generate samples of a random field which all satisfy a certain constraint, such as the presence of a galaxy in a specific location.

% \subsection{Constrained realizations}

\textcite[]{bertschingerPathIntegralMethods1987} pioneered the use of path integrals in order to generate \emph{constrained realizations} of perturbation fields: these are realizations of the field --- points in the statistical ensemble --- which satisfy some specific characteristic, such as the presence of a galaxy in a specific location. 

This allows for the statistical study of the structure \emph{around} the peak of the density perturbation, as opposed to only considering the statistics of the peak distribution. 

% Perturbative methods (i.\ e. linearization) work well in the initial stages, then the nonlinearity kicks in and the higher order terms become very relevant: Monte Carlo methods are then more suitable to calculate the functional integrals. 


% They are able to put constrains on the realizations of the Gaussian random field! 
% BBKS gives us peaks; the path integral approach allows us to more precisely estimate the surrounding  distribution, by the use of constraints. 

% In \cite[]{hoffmanConstrainedRealizationsGaussian1991} an improved algorithm for constrained realizations of Gaussian fields is presented.

% \todo[inline]{To understand: what constrained realizations are practically useful? Do we impose the presence of a (proto-galaxy?) and generate the density distribution around it?} 

% \textcite[]{bertschingerPathIntegralMethods1987} found a method with complexity \(\order{(N_c^2 + 1) N}\) working in Fourier space (so, in a plane wave basis), 
% Binney and Quinn (1990) improved upon it by working in spherical harmonics --- 
% for certain symmetric types of constrains this decreases \(N_c\) significantly. 

% \textcite[]{hoffmanConstrainedRealizationsGaussian1991} work by constraining the Fourier \emph{phases} of the components of the random field. 

\subsection{Press-Schechter theory}

Press-Schechter theory is a way to calculate the distribution of virialized objects (i.\ e.\ galaxies) in a perturbative fashion.
Virialization is a deeply nonlinear process; however it can be shown that when the linearized density perturbation reaches a critical value of \(\delta _c \approx 1.686\) the corresponding true nonlinear halo has virialized. 

\textcite[]{matarreseAbundanceHighRedshift2000} applied this approach to a mildly non-Gaussian density perturbation field (with only a quadratic term) in order to study the abundance of high-redshift galaxies, finding analytic results with the aid of the path integral formalism.

% If we perturb the density we need \(\abs{\epsilon} \lesssim \num{e-2}\), if we perturb the gravitational field we need \(\abs{\epsilon } \gtrsim \num{e2}\), in either case these are needed in order to see a significant departure from the Gaussian case. 
% The latter statements tells us that non-Gaussianity predicted by inflationary models would be undetectable from structure formation. 

% \todo[inline]{Does equation 51 solve the problem of halos-inside-halos which was mentioned as an issue in early Press-Schechter theory?}

% Section 5: using high-\(z\) galaxies is advantageous because ``they directly sample the galaxy scale, and are always in virialized halos''. I get the fist point, but not the second: are more recent galaxies not in virialized halos? 

In order to account for the scale of the growing mode of the linear perturbations they give a redshift-dependence to the critical density: fixing \(\Delta _c = \num{1.686}\) they write \(\delta _c = \Delta _c / D(z_c  | \Omega_{0, m}, \Omega_{0, \Lambda })\), where \(D\) is the linear growth factor: \(D^{-1}\) increases with redshift. 

This means that at higher \(z\) it is harder to form virialized objects, but simultaneously the density PDF is more sensitive to non-Gaussianity.
This can be seen graphically in figures 4 and 5 of the same paper.\footnote{They refer to two different models, denoted as \(A\) and \(B\): in the first the density field is perturbed, in the second the gravitational field is perturbed. Nowadays, model \(B\) has been found to be the most useful one.}
% So, \(\delta _c\) increases with redshift, therefore we see from equation 66 that the skewness term becomes less and less relevant. 
% This can be seen in figs.\ 4 and 5 as well. 

% Connection with observation! 
% We have a sample of 6 \(z \sim 5 \divisionsymbol 6  \) galaxies, whose masses, SFR and \(\sigma _v\) are estimated from spectroscopic data.
% Approximately speaking, from the amount of galaxies found per area surveyes, at this redshift we find \(\sim 1\) galaxy per \SI{3e-4}{\deg^2}. 

% Estimating the number of galaxies formed with masses within \(\num{2e10} M_{\odot} < M < \num{4e11}M_{\odot}\) and formation redshifts within \(6 < z_c < 8\) yields a number density of galaxies about 16 times lower than the observed value; non-Gaussianity can raise the tail of the density distribution to give the required order-10 increase of galaxy formation. 

% Precise mass determination is crucial to figure out whether we actually need non-Gaussianity to explain the data. 

\subsection{The bispectrum}

As we will explore in more detail later, the two-point function and its associated power spectrum completely characterize a Gaussian field: all the higher-order \(n\)-point correlation functions can be derived from the two-point one.
Since we want to characterize non-Gaussianity, then, we define the simplest object which allows us to do so: the 3-point correlation function, and its associated \emph{bispectrum}, defined by the relation 
%
\begin{align}
\expval{ \delta (\vec{k}_1 ) \delta (\vec{k}_2 ) \delta (\vec{k}_3 ) }
= (2 \pi )^3 \delta^{(3)} (\vec{k}_1 + \vec{k}_2 + \vec{k}_3 ) B (k_1, k_2, k_3)
\,.
\end{align}

We stress that this kind of statistical tool can be applied to any field; in modern analyses the bispectrum associated with the gravitational field \cite[eq.\ 2]{celoriaPrimordialNonGaussianity2018} \(B_\Phi \) is used.

This kind of correlation function then can be used to estimate the nongaussianity in the gravitational field distribution: it can be shown that if we consider a linear + quadratic model like that in equation \eqref{eq:perturbed-gaussian-field} (with \(g_{NL} = 0\)) we will have 
%
\begin{align}
B_{\Phi } (k_1, k_2, k_3 ) = 2 f_{NL}
\qty(B_\Phi (k_1 ) B_\Phi (k_2 ) + B_\Phi (k_2 ) B_\Phi (k_3) + B_\Phi (k_1 ) B_\Phi (k_3 ))
\,,
\end{align}
%
where \(B_\Phi (k)\) is the power spectrum. 
This allows us to observationally compute \(f_{NL}\),  \cite[]{planckcollaborationPlanck2018Results2020}. 

% Two point correlation function: 
% %
% \begin{align}
% 1 + \xi (r_{12} ) = \frac{ \dd{P}}{ \dd{P} _{\text{indep}}} = \frac{ \dd{P}}{ n^2 \dd{V_1} \dd{V_2}}
% \,.
% \end{align}
%

% Fractal dimension! 
% The number of galaxies within a radius \(R\) around a given one scales like \(R^{3-\gamma }\).

% Hierarchical models: \(N\)-point correlation functions can be calculated from the two-point one. 

% Bias model: \(\delta _g = b \delta \) with constant \(b\), where \(\delta_g \) is the density perturbation for galaxies and \(\delta \) is the one for dark matter.

% Power spectrum definition, which by Wiener-Khinchin is the Fourier transform of the two-point correlation function. 
% Expression for \(\xi \) in terms of \(P\) and Bessel functions as a single integral. 

\end{document}
