\documentclass[main.tex]{subfiles}
\begin{document}

\section{The Dirac Equation}

\marginpar{Saturday\\ 2020-3-28, \\ compiled \\ \today}

The Klein Gordon equation, which we discussed in the previous lectures, has two main issues: 
\begin{enumerate}
  \item It is a second order equation, since we started from the relativistic dispersion relation \(E^2 = M^2 + \abs{\vec{p}}^2\), so it admits a negative as well as a positive energy solution: \(E = \pm \omega_{p}\). 
  \item The charge associated with its 4-current density \(J^{\mu }\) is not positive definite: 
  %
  \begin{align}
  Q = \int \dd[3]{x} J^{0}(\vec{x}, t) 
  \,
  \end{align}
  %
  can be negative. 
\end{enumerate}

In order to clarify the problem with these, we discussed the Klein Paradox, in which there is a violation of unitarity for a scattering process: the reflection probability was \(>1\) while the transmission probability was negative. 

Dirac, in 1928, tried a different approach. 

\subsection{Historical derivation of the Dirac equation}

We want to build an equation in the form 
%
\begin{align}
i \pdv{}{t} \psi  = H_D \psi 
\,,
\end{align}
%
for some Dirac Hamiltonian \(H_D\), which we require to be first-order in the space derivatives and the mass, so that our equation can be covariant: this in general will be written as 
%
\begin{align}
H_D = -i \vec{\alpha} \cdot \vec{\nabla} + \beta M = \vec{\alpha} \cdot \qty(-i \vec{\nabla}) + \beta M
\,,
\end{align}
%
for some yet to be determined 4 coefficients \(\vec{\alpha}\) and \(\beta \).

Why are we introducing the \(i\)? This formulation is equivalent to saying that the energy \(E\) is given by \(\vec{\alpha} \cdot \vec{p} + \beta M\), since \(\vec{p} = - i \vec{\nabla}\). 

We are assuming the coefficients to be constant, we shall see that this hypothesis works out. Also, as we shall these cannot be numbers, but instead they are matrices: for now, all this means is that we need to be careful when manipulating them, since in general they will not commute. 

In order to determine \(\vec{\alpha }\) and \(\beta \) we impose the conditions: 
\begin{enumerate}
  \item the Dirac Hamiltonian \(H_D\) is hermitian, since it needs to describe the physical property of energy, therefore it is an observable;
  \item if \(\psi \) solves the Dirac equation, then it also solves the KG equation. 
\end{enumerate}

Actually, KG solutions also Dirac solutions in general. 

The first condition can be written as \(H = H ^\dag\), but to find out what it means for the coefficients \(\vec{\alpha }\) and \(\beta \) we need to know what \(\vec{\nabla} ^\dag\): since we know that momentum \(\vec{p} = -i \vec{\nabla}\) is self adjoint, we must have \(\vec{p} ^\dag = (-i) ^\dag \vec{\nabla} ^\dag = i \vec{\nabla} ^\dag \overset{!}{=} -i \vec{\nabla} = \vec{p} \),
which means that \(\vec{\nabla} ^\dag = - \vec{\nabla}\).
So, we get 
%
\begin{subequations}
\begin{align}
H ^\dag &= (-i) ^\dag \vec{\alpha} ^\dag \cdot \vec{\nabla} ^\dag + \beta ^\dag M ^\dag  \\
&= -i \alpha^{*} \cdot \vec{\nabla} + \beta^{*} M
\,,
\end{align}
\end{subequations}
%
since \(M\) is real.\footnote{In the professor's notes this is done explicitly by integrating by parts: this method can be adapted to look like that, since one can use integration by parts to show that for any wavefunctions \(\phi \) and \(\psi \) we have \(\braket{\phi }{\nabla \psi } + \braket{\nabla \phi}{\psi } = 0\). Then, the only difference between the approaches is whether we only integrate by parts to get the adjoint of \(\nabla\) or the whole of \(H_D\). }
Therefore, the coefficients must satisfy \(\vec{a}^{*} = \vec{\alpha}\) and \(\beta^{*} = \beta \) themselves. 

The other condition, consistency with the KG equation, means that when we square the Dirac time derivative operator 
%
\begin{align}
\pdv{}{t} = -i H_D
\,
\end{align}
%
we should get the KG square time- derivative operator 
%
\begin{align}
\pdv[2]{}{t} = \nabla^2 + M^2
\,.
\end{align}

So, we find 
%
\begin{subequations}
\begin{align}
\nabla^2 + M^2 &\overset{!}{=} (-i H_D)^2 = - H_D^2  \\
&= -\qty(-i \alpha_{i}  \nabla_{i} + \beta ) \qty(-i \alpha_{j} \nabla_{j} + \beta )  \\
&= \alpha_{i} \alpha_{j} \nabla_{i} \nabla_{j} + i \qty(\alpha_{i} \beta  + \beta \alpha_{i}) \nabla_{i} + \beta^2  \\
&= \frac{1}{2} \qty{\alpha_{i}, \alpha_{j}} \nabla_{i} \nabla_{j} 
+ i \qty{\alpha_{i}, \beta } \nabla_{i} + \beta^2
\,,
\end{align}
\end{subequations}
%
where we introduced the anticommutator bracket notation: 
%
\begin{align}
\qty{A, B} = AB + BA
\qquad \text{while} \qquad
\qty[A, B] = AB - BA
\,.
\end{align}

So, in order for the equations to be equivalent we need to impose 
%
\begin{align}
\frac{1}{2}\qty{\alpha_{i}, \alpha_{j}} = \delta_{ij}
\qquad \qquad 
\qty{\alpha_{i}, \beta } = 0
\qquad \qquad 
\beta^2 = M^2
\,.
\end{align}

This means \(\alpha_{i}\) and \(\beta \) cannot be real or complex numbers: for complex numbers \(x, y\) we have \(\qty{x, y} = 2 xy \),  since for them multiplication is commutative. 

Specifically, they must be matrices in an \(N\)-dimensional vector space, called a spinorial space. 
So, \(\alpha_{i}\) and \(\beta \) are \(N \times N\) matrices, while the wavefunction \(\psi \) is an \(N\) dimensional vector (spinor). \(N\) is yet to be determined.

They must be Hermitian matrices, since they satisfy \(\alpha_{i} ^\dag = \alpha_{i}\) and \(\beta ^\dag = \beta \).

We must have \(\alpha_{i}^2 = \frac{1}{2} \qty{\alpha_{i}, \alpha_{i}} = \mathbb{1}\), where \(\mathbb{1}\) is the \(N\) dimensional identity matrix. Also, \(\beta^2 = \mathbb{1}\). 
If we write \(\alpha_{i}\) and \(\beta \) in diagonal form, which we can do since they are Hermitian, we get their real eigenvalues on the diagonal. If we square them we get the identity, therefore they must all be \(\pm 1\). 

Now, let us show that these are traceless: call \(c_{\mu }\) one of the four \(\qty(\beta ,\alpha_{i})\). Then, we know that \(\qty{c_{\mu }, c_{\nu }} = 2 \delta_{\mu \nu }\).
So, we do the following manipulation: take \(c_{\mu }\) and \(c_{\nu }\), with \(\nu \neq \mu \):
%
\begin{subequations}
\begin{align}
\Tr(c_{\mu }) &= \Tr(c_{\mu } c_{\nu } c_{\nu })  \marginnote{\(c_{\nu }^2 = \mathbb{1}\)}\\
&= \Tr(-c_{\nu } c_{\mu } c_{\nu }) \marginnote{\(\qty{c_{\mu }, c_{\nu }} = 0\), so \(c_{\mu } c_{\nu } = - c_{\nu } c_{\mu }\)}  \\
&= \Tr(-c_{\mu } c_{\nu } c_{\nu })  \marginnote{Cyclic property of the trace, and linearity of the trace}[.7cm]\\
&= - \Tr(c_{\mu })
\,,
\end{align}
\end{subequations}
%
so \(\Tr(c_{\mu }) = - \Tr(c_{\mu }) \implies \Tr(c_{\mu }) = 0\). 
Since the trace is the sum of the eigenvalues, which are \(\pm 1\), the dimension must be even. 

So, our simplest guess will be \(N=2\): a basis for Hermitian complex matrices is \(\qty{\mathbb{1}, \sigma_{i}}\) where \(\sigma_{i}\) are the Pauli matrices.
However, \(\mathbb{1}\) is not traceless: so our \(c_{\mu }\) can only be written as \(c_{\mu } = \vec{c} \cdot \vec{\sigma}\).

Now, our \(c_{\mu }\) must be linearly independent over \(\mathbb{C}\): if they were not, say because \(c_{\mu } = z c_{\nu }\), with \(\mu \neq \nu \) and \(z \in \mathbb{C}\), then the anticommutation would read 
%
\begin{align}
\qty{c_{\mu }, c_{\nu }} = \qty{z c_{\nu }, c_{\nu }} = z \mathbb{1}  \neq 0
\,,
\end{align}
%
a contradiction. 
We only have three linearly independent Pauli matrices \(\sigma_{i}\) to express four \(c_{\mu }\), so this cannot work. 

Do however note that if \(M=0\) then we do not need the \(\beta \) matrix since the term multiplying it goes to zero, so the only matrices we need are the three \(\alpha_{i}\): in the massless case, then, we can use the Pauli matrices, setting \(\sigma_{i} = \alpha_{i}\) satisfies all our requirements, since \(\qty{\sigma_{i}, \sigma_{j}} = 2 \delta_{ij}\). 

The next possible dimensionality is \(N=4\), and we can use the following matrices: 
%
\begin{subequations}
\begin{align}
\alpha_{i} = \left[\begin{array}{cc}
0 & \sigma_{i} \\ 
\sigma_{i} & 0
\end{array}\right]
\qquad \text{and} \qquad
\beta = \left[\begin{array}{cc}
\mathbb{1} & 0 \\ 
0 & -\mathbb{1}
\end{array}\right]  
\,.
\end{align}
\end{subequations}

These are self adjoint since the Pauli matrices are, manifestly traceless, and they satisfy the anticommutation relations. 

\begin{proof}
We expand the relation \(\qty{\alpha_{i}, \alpha_{j}}\): if we write \(\alpha_{i} \alpha_{j}\) we get 
%
\begin{subequations}
\begin{align}
\alpha_{i} \alpha_{j} = 
\left[\begin{array}{cc}
0 & \sigma_{i} \\ 
\sigma_{i} & 0
\end{array}\right]
\left[\begin{array}{cc}
0 & \sigma_{j} \\ 
\sigma_{j} & 0
\end{array}\right]
= \left[\begin{array}{cc}
\sigma_{i} \sigma_{j} & 0 \\ 
0 & \sigma_{i} \sigma_{j}
\end{array}\right]
\,,
\end{align}
\end{subequations}
%
therefore 
%
\begin{subequations}
\begin{align}
\qty{\alpha_{i}, \alpha_{j}} = \left[\begin{array}{cc}
\qty{\sigma_{i}, \sigma_{j}} & 0 \\ 
0 & \qty{\sigma_{i}, \sigma_{j}}
\end{array}\right]
= \qty{\sigma_{i}, \sigma_{j}} \mathbb{1}_{4}
\,,
\end{align}
\end{subequations}
%
but we know that \(\qty{\sigma_{i}, \sigma_{j}} = 2 \delta_{ij}\), so we have verified the anticommutation relations between the \(\alpha_{i}\). 

To see that \(\beta^2 = \mathbb{1}_{4}\) is immediate since it is already diagonal, so we only need to show \(\qty{\alpha_{i}, \beta } = 0\). We have 
%
\begin{subequations}
\begin{align}
\alpha_{i} \beta =
\left[\begin{array}{cc}
0 & \sigma_{i} \\ 
\sigma_{i} & 0
\end{array}\right]
\left[\begin{array}{cc}
\mathbb{1} & 0 \\ 
0 & -\mathbb{1}
\end{array}\right]
&= 
\left[\begin{array}{cc}
0 & -\sigma_{i} \\ 
\sigma_{i} & 0
\end{array}\right] \\
\beta \alpha_{i} =
\left[\begin{array}{cc}
\mathbb{1} & 0 \\ 
0 & -\mathbb{1}
\end{array}\right]
\left[\begin{array}{cc}
0 & \sigma_{i} \\ 
\sigma_{i} & 0
\end{array}\right]
&= 
\left[\begin{array}{cc}
0 & \sigma_{i} \\ 
-\sigma_{i} & 0
\end{array}\right]
\,,
\end{align}
\end{subequations}
%
so the sum \(\alpha_{i} \beta + \beta \alpha_{i}\) is zero, which proves our statement. 
\end{proof}

\subsubsection{The \(\gamma \) matrices}

It is then conventional to define the matrices 
%
\begin{subequations}
\begin{align}
\gamma^{0} = \beta = \left[\begin{array}{cc}
\mathbb{1} & 0 \\ 
0 & -\mathbb{1}
\end{array}\right]
\qquad \text{and} \qquad
\gamma^{i} = \beta \alpha_{i} = \left[\begin{array}{cc}
0 & \sigma_{i} \\ 
-\sigma_{i} & 0
\end{array}\right]
\,,
\end{align}
\end{subequations}
%
which obey the following properties: 
\begin{enumerate}
  \item \(\gamma^{0} = (\gamma^{0}) ^\dag\), while \(\gamma^{i} = - (\gamma^{i} ) ^\dag\);
  \item \(\qty{\gamma^{\mu }, \gamma^{\nu }} = 2 \eta^{\mu \nu }\), specifically \((\gamma^{0})^2 = \mathbb{1}_{4}\) and \((\gamma^{i})^2 = - \mathbb{1}_{4}\). 
\end{enumerate}

We can then interpret this collection of matrices as a 4-vector. 
We can rewrite the Dirac equation using them: we multiply it by \(\beta \) to get 
%
\begin{subequations} \label{eq:dirac-equation-from-ansatz-to-gamma}
\begin{align}
i \partial_0 \psi &= \qty(-i \alpha_{i} \partial_{i}+ \beta M ) \psi  \\
i \beta \partial_0 \psi &= \qty(-i \beta \alpha_{i} \partial_{i} + \beta^2 M) \psi  \\
i \gamma^{0} \partial_0 \psi &= \qty(- \gamma^{i}\partial_{i} + \beta^2 M) \psi  \\
\qty(i \gamma^{\mu } \partial_{\mu } - M ) \psi &= 0 
\,.
\end{align}
\end{subequations}

This looks simple, but recall that \(\gamma^{\mu }\) are \(4 \times 4\) matrices and \(\psi \) is a 4D spinor: if we write this explicitly using the spinor indices, for which we use the Hebrew letters \(\aleph\) nd \(\beth\) (aleph and beth\footnote{Since this notation will only be used here, it does not matter if it is a little inconvenient. I did not use greek or latin letters since they both already have meaning in the conventional notation.}), we get 
%
\begin{align}
\qty(i \gamma^{\mu }_{\aleph \beth} - M \delta_{\aleph \beth}) \psi_{\beth} = 0 
\,,
\end{align}
%
which is a set of 4 equations, indexed by the free index \(\aleph\).
Since the \(\gamma \) matrices are not diagonal, the components \(\psi_{\beth}\) are mixed in the equation. 

If we introduce the slashed notation \(\slashed{p} \overset{\text{def}}{=} \gamma^{\mu }p_{\mu }\). 

With this notation, the Dirac equation reads 
%
\boxalign{
\begin{align}
\qty(i \slashed{\partial} -M) \psi = 0
\,.
\end{align}}

\subsubsection{Representations of \(\gamma \)-matrices}

The way we defined the \(\gamma \) matrices was arbitrary, and in fact there are other possible equivalent definitions which are also physically useful. 

In general, for any unitary matrix \(C\) we can move to the new representation 
%
\begin{align}
\widetilde{\gamma}^{\mu } =C^{-1} \gamma^{\mu } C
\,.
\end{align}

How do we prove that the physical results are the same?
The Dirac equation is in the form \(A \psi =0\), and if we show that for an equation in this form \(C^{-1} A C\) is as good as \(A\) then we are done: in \(A = i \slashed{\partial} - M \mathbb{1}\) the \(M \mathbb{1}\) term is unaffected since it commutes with the matrix, the derivative is unaffected since the \(C\) matrix is assumed to be constant.
But then, if we want to use \( \widetilde{A} = C^{-1}A C\), we will find solutions to \(C^{-1} A C C^{-1} \psi = \widetilde{A} \widetilde{\psi}\), where \(\widetilde{\psi} = C^{-1} \psi \): we will see later that the physical observables corresponding to spinors are related to their contractions, and indeed if we take the square modulus after applying a unitary transformation it is unchanged. 

The Dirac representation we gave before is usually used when dealing with the nonrelativistic limit, while the one we now show is called the relativistic, or Weyl, or chiral, representation. 
We use the matrix which is known in quantum information as the Hadamard gate:
%
\begin{subequations}
\begin{align}
C = \frac{1}{\sqrt{2}} \left[\begin{array}{cc}
1 & 1 \\ 
-1 & 1
\end{array}\right]
\,
\end{align}
\end{subequations}
%
we can move to the representation 
%
\begin{subequations}
\begin{align}
\gamma^{\mu } = \qty(\left[\begin{array}{cc}
0 & \mathbb{1} \\ 
\mathbb{1} & 0
\end{array}\right], \left[\begin{array}{cc}
0 & \sigma_{i} \\ 
- \sigma_{i} & 0
\end{array}\right])
\,.
\end{align}
\end{subequations}
%
\begin{proof}
We multiply, writing \(1\) for \(\mathbb{1}\) and \(0\) for the 0 matrix for simplicity: for \(\gamma^{0}\) we get 
%
\begin{subequations}
\begin{align}
C^{-1} \gamma^{0} C &= \frac{1}{2} \left[\begin{array}{cc}
1 & -1 \\ 
1 & 1
\end{array}\right]
\left[\begin{array}{cc}
1 & 0 \\ 
0 & -1
\end{array}\right]
\left[\begin{array}{cc}
1 & 1 \\ 
-1 & 1
\end{array}\right]  \\
&= \frac{1}{2} \left[\begin{array}{cc}
1 & -1 \\ 
1 & 1
\end{array}\right] 
\left[\begin{array}{cc}
1 & 1 \\ 
1 & -1
\end{array}\right]  \\
&= \frac{1}{2} \left[\begin{array}{cc}
0 & 2 \\ 
2 & 0
\end{array}\right] = \left[\begin{array}{cc}
0 & 1 \\ 
1 & 0
\end{array}\right]
\,,
\end{align}
\end{subequations}
%
while for \(\gamma^{i}\) we have 
%
\begin{subequations}
\begin{align}
C^{-1} \gamma^{i} C &= \frac{1}{2} \left[\begin{array}{cc}
1 & 1 \\ 
-1 & 1
\end{array}\right]
\left[\begin{array}{cc}
0 & \sigma_{i} \\ 
- \sigma_{i} & 0
\end{array}\right] 
\left[\begin{array}{cc}
1 & -1 \\ 
1 & 1
\end{array}\right]  \\
&= \frac{1}{2} 
\left[\begin{array}{cc}
1 & 1 \\ 
-1 & 1
\end{array}\right]
\left[\begin{array}{cc}
\sigma_i  & \sigma_i  \\ 
- \sigma_i  & \sigma_i 
\end{array}\right]  \\
&= \left[\begin{array}{cc}
0 & \sigma_i  \\ 
-\sigma_i  & 0
\end{array}\right]
\,.
\end{align}
\end{subequations}
\end{proof}

The Dirac equation is consistent with the Klein Gordon equation: we can multiply it by the conjugate of the Dirac operator, \(-(i \slashed{\partial}+M)\), to get 
%
\begin{subequations}
\begin{align}
- \qty(i \slashed{\partial}+M) \qty(i \slashed{\partial}-M) \psi  &= 0\\
\qty( \gamma^{\mu } \gamma^{\nu } \partial_{\mu } \partial_{\nu } + M^2  ) &= 0   \\
\qty(\square + M^2) \psi &=0
\,,
\end{align}
\end{subequations}
%
which is equivalent to the Klein-Gordon equation since when we compute \(\gamma^{ \mu }  \gamma^{\nu } \partial_{\mu } \partial_{\nu }\) we only have the symmetric part, since the partial derivatives commute, and \(\frac{1}{2} \qty{\gamma^{\mu }, \gamma^{\nu }} = \eta^{\mu \nu }\). 

The Klein-Gordon equation is then diagonal in the spinorial space: by this manipulation we have shown that the KG operator is proportional to the identity. 

\end{document}

